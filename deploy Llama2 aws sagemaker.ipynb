{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri, HuggingFaceModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data  = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'AWS_DEFAULT_REGION', 'ROLE_NAME', 'HF_TOKEN'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = config_data['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = config_data['AWS_SECRET_ACCESS_KEY']\n",
    "AWS_DEFAULT_REGION = config_data['AWS_DEFAULT_REGION']\n",
    "ROLE_NAME = config_data['ROLE_NAME']\n",
    "HF_TOKEN = config_data['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up AWS credentials with environment variables\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = AWS_ACCESS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_ACCESS_KEY\n",
    "os.environ['AWS_DEFAULT_REGION'] = AWS_DEFAULT_REGION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role() # this will not work in local environments. it supports only in sagemaker notebook instances.\n",
    "    # That is the reason why we try to establish connection with iam using boto3\n",
    "except ValueError as e:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName = ROLE_NAME)['Role']['Arn']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the llm image uri\n",
    "\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "    \"huggingface\",\n",
    "    version = \"0.9.3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker config\n",
    "\n",
    "instance_type =\"ml.g5.xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 600\n",
    "endpoint_name = \"llama-2-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model and Endpoint configuration parameter\n",
    "\n",
    "config = {\n",
    "    'HF_MODEL_ID': \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    'SM_NUM_GPUS' :json.dumps(number_of_gpu),\n",
    "    'MAX_INPUT_LENGTH': json.dumps(2048),\n",
    "    'MAX_TOTAL_TOKENS' : json.dumps(4096),\n",
    "    'MAX_BATCH_TOTAL_TOKENS': json.dumps(8192),\n",
    "    'HUGGINGFACE_HUB_TOKEN': HF_TOKEN,\n",
    "    'HF_MODEL_QUNATIZE': 'bitsandbytes',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Huggingfacemodel with the image uri\n",
    "\n",
    "llm_model = HuggingFaceModel(\n",
    "    name= 'llama-2-model',\n",
    "    role = role,\n",
    "    image_uri= llm_image,\n",
    "    env = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: llama-2-model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deploy model to an endpoint\n",
    "llm = llm_model.deploy(\n",
    "  endpoint_name=endpoint_name,\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")\n",
    "\n",
    "print('\\nLLAMA 2 model deployed to Sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
